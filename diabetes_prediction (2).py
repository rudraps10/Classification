# -*- coding: utf-8 -*-
"""diabetes prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WN2KGYJkBpauA2_0W0q79KvmToJbrl_c
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df= pd.read_csv('/content/diabetes.csv')

df.shape

df.head()

df.tail(7)

df.sample(7)

df.info()

df.describe()

(df==0).sum()

import seaborn as sns
import matplotlib.pyplot as plt


correlation = df.corr()['Outcome'].sort_values(ascending=False)
print(correlation)

sns.boxplot(x='Outcome', y='Insulin', data=df)
plt.title("Insulin vs Outcome")
plt.show()

for col in df.columns:
  plt.figure(figsize=(6,4))
  sns.displot(data=df,x=col,kde=True)
  plt.title(f'Distribution of {col}')
  plt.show()

for col in df.columns:
  plt.figure(figsize=(6,4))
  sns.boxplot(data=df,x=col)
  plt.title(f'Distribution of {col}')
  plt.show()

for col in df.columns:
  plt.figure(figsize=(3,2))
  sns.displot(data=df,x=col,kde=True)
  plt.title(f'Distribution of {col}')
  plt.show()

features = df.drop('Outcome', axis=1)
for col in features.columns:
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    df[col] = df[col].apply(lambda x: lower_bound if x < lower_bound else upper_bound if x > upper_bound else x)

plt.figure(figsize=(10,8))
sns.heatmap(df.corr(), annot=True, fmt=".2f", cmap="coolwarm", square=True)
plt.title("Correlation Heatmap")
plt.show()

sns.pairplot(df, hue='Outcome', vars=['Glucose', 'BMI', 'Age', 'BloodPressure'])
plt.show()

from sklearn.model_selection import train_test_split

X=df.drop('Outcome',axis=1)
y=df['Outcome']

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

from sklearn.model_selection import cross_val_score


from sklearn.metrics import r2_score

from sklearn.preprocessing import PowerTransformer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

cols_to_fill = ["Glucose","BloodPressure","SkinThickness","Insulin","BMI"]
means = {}
for col in cols_to_fill:
    mean_value = X_train[X_train[col] != 0][col].mean()
    means[col] = mean_value
    X_train[col] = X_train[col].replace(0, mean_value)

for col in cols_to_fill:
    X_test[col] = X_test[col].replace(0, means[col])

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_train=sc.fit_transform(X_train)
X_test=sc.transform(X_test)

scores=[]
for i in range(1,60):
  knn = KNeighborsClassifier(n_neighbors=i)
  knn.fit(X_train, y_train)
  y_pred= knn.predict(X_test)
  scores.append(accuracy_score(y_test, y_pred))

plt.plot(range(1,60),scores)

knn=KNeighborsClassifier(n_neighbors=40)
knn.fit(X_train,y_train)
y_pred=knn.predict(X_test)
print(accuracy_score(y_test,y_pred))

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)
y_pred1 = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred1))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred1))
print("Classification Report:\n", classification_report(y_test, y_pred1))

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Classification Report:\n", classification_report(y_test, y_pred_rf))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))